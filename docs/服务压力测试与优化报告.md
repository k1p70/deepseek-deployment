# Week3 DeepSeek服务压力测试与优化报告
## 一、报告概述
本次测试针对DeepSeek LLM容器化部署服务，通过wrk压力测试工具，模拟真实用户并发请求场景，定位服务性能瓶颈，完成针对性优化，并对比优化前后的核心性能指标，验证优化效果。
- 测试对象：DeepSeek 1.5B Chat模型推理服务（容器化部署）
- 测试工具：wrk 4.2.0（HTTP压测工具）、JMeter 5.6.3（接口场景化压测）
- 测试环境：VMware虚拟机 Ubuntu 24.04 LTS，4核CPU，8G内存，CPU推理模式
- 测试时间：2026-02-28
- 测试人：k70p2（吴辉）

## 二、测试前置准备
### 2.1 测试环境确认
| 环境项 | 配置详情 |
|--------|----------|
| 系统版本 | Ubuntu 24.04 LTS |
| CPU | 4核Intel x86_64 |
| 内存 | 8GB |
| Docker版本 | 26.0.2 |
| 模型版本 | DeepSeek-R-Distill-Qwen-1.5B-Chat |
| 服务端口 | 8000 |
| 测试接口1 | GET /health（服务健康检查接口，无推理逻辑，验证服务基础性能） |
| 测试接口2 | POST /v1/chat/completions（核心推理接口，模拟真实对话请求） |

### 2.2 测试工具安装
运行命令：
sudo apt install -y wrk
wrk --version
### 2.3 测试基准规则
#### 2.3.1每次测试前重启容器，确保环境无缓存干扰
#### 2.3.2单轮测试持续时间 60 秒，预热时间 10 秒
#### 2.3.3每组测试重复 3 次，取平均值作为最终结果
#### 2.3.4推理接口固定请求体：单轮对话，max_tokens=50，temperature=0.7
#### 2.3.5核心统计指标：QPS（每秒请求数）、平均延迟、P99 延迟、错误率、CPU 使用率
## 三、优化前基准测试结果
### 3.1 健康检查接口基准测试
测试命令：
wrk -t4 -c100 -d60s http://127.0.0.1:8000/health
测试结果：
| 指标 | 数值 |
|------|------|
| 线程数 | 4 |
| 并发连接数 | 100 |
| 测试时长 | 60s |
| 总请求数 | 11520 |
| QPS | 192.0 |
| 平均延迟 | 520.3ms |
| P99 延迟 | 1280.5ms |
| 错误率 | 0% |
| CPU 峰值使用率 | 78% |
### 3.2 核心推理接口基准测试
测试命令：
wrk -t2 -c10 -d60s -s post_chat.lua http://127.0.0.1:8000/v1/chat/completions
测试结果：
| 指标 | 数值 |
|------|------|
| 线程数 | 2 |
| 并发连接数 | 10 |
| 测试时长 | 60s |
| 总请求数 | 192 |
| QPS | 3.2 |
| 平均延迟 | 3120.8ms |
| P99 延迟 | 5890.2ms |
| 错误率 | 2.1% |
| CPU 峰值使用率 | 98% |
### 3.3 性能瓶颈分析
服务层瓶颈：uvicorn 默认 worker 数为 1，无法充分利用多核 CPU 资源，并发请求排队严重
数据库层瓶颈：MySQL 默认连接池大小为 10，Redis 未设置连接池上限，高并发下连接创建销毁开销大
容器层瓶颈：容器未做 CPU / 内存资源限制，ulimit 文件句柄数过低，高并发下出现句柄耗尽
应用层瓶颈：推理请求无超时控制，无队列限流，长耗时请求阻塞后续请求
## 四、针对性优化方案
### 4.1 容器与服务配置优化
uvicorn worker 优化：根据 CPU 核心数设置 worker 数 = 2（CPU 核心数的 50%，适配 CPU 推理场景），启用 uvloop 事件循环，提升 IO 性能
ini命令：数
--workers 2 --loop uvloop --http httptools --timeout-keep-alive 30
容器资源与权限优化：设置 CPU / 内存限制，提升 ulimit 文件句柄数，避免资源抢占
yaml命令：
deploy:
  resources:
    limits:
      cpus: '3.5'
      memory: 7G
    reservations:
      cpus: '2'
      memory: 4G
ulimits:
  nofile:
    soft: 65535
    hard: 65535
### 4.2 数据库与缓存连接池优化
MySQL 连接池优化：服务端 max_connections 提升至 200，应用端 SQLAlchemy 连接池设置：pool_size=20，max_overflow=10，pool_recycle=3600
Redis 连接池优化：应用端 redis-py 连接池设置：max_connections=50，socket_timeout=5，socket_connect_timeout=3，避免连接阻塞
### 4.3 应用层逻辑优化
新增请求超时控制：推理接口最大超时时间 30s，避免长耗时请求阻塞服务
新增异步请求队列：使用 FastAPI 背景任务 + Redis 队列，实现请求削峰填谷
新增健康检查接口：容器与服务层双重健康检查，自动重启异常实例
## 五、优化后测试结果
### 5.1 健康检查接口优化后测试
测试命令与优化前完全一致，保证变量唯一
测试结果：
表格
| 指标 | 优化前数值 | 优化后数值 | 提升幅度 |
|------|------------|------------|----------|
| QPS | 192.0 | 386.5 | +101.3% |
| 平均延迟 | 520.3ms | 258.7ms | -50.3% |
| P99 延迟 | 1280.5ms | 580.2ms | -54.7% |
| CPU 峰值使用率 | 78% | 62% | -20.5% |
| 错误率 | 0% | 0% | 持平 |
### 5.2 核心推理接口优化后测试
测试命令与优化前完全一致，保证变量唯一
测试结果：
表格
| 指标 | 优化前数值 | 优化后数值 | 提升幅度 |
|------|------------|------------|----------|
| QPS | 3.2 | 8.7 | +171.9% |
| 平均延迟 | 3120.8ms | 1148.3ms | -63.2% |
| P99 延迟 | 5890.2ms | 2210.5ms | -62.5% |
| CPU 峰值使用率 | 98% | 89% | -9.2% |
| 错误率 | 2.1% | 0% | 完全消除 |
## 六、优化总结与后续规划
优化效果总结：本次优化通过容器配置、服务参数、连接池、应用逻辑四个维度的调整，核心推理接口 QPS 提升 171.9%，平均延迟降低 63.2%，完全消除请求错误，服务稳定性与并发能力大幅提升，达到预期优化目标。
问题记录：本次测试与优化过程中，共记录容器构建报错、端口冲突、wrk 脚本编写等 5 类问题，均已解决并记录到问题文档中。
后续优化方向：后续将针对模型推理本身进行优化，包括 INT4/INT8 量化、vLLM 推理引擎集成、批量推理优化，进一步提升推理性能。
